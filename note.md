# ARCHitects 核心方案要点

## 1. 数据准备

### 数据集

- 官方ARC-AGI1数据集（400训练+400公开评估+100私有评估）
- Re-ARC：通过DSL生成的扩展数据集（400任务→大量示例）
- Concept-ARC：176个额外概念任务
- ARC-Heavy：LLM生成的合成任务

### 数据表示

- 自定义标记化：仅64个标记（字母A-Z/a-z、数字0-9、特殊标记）
- 避免标准BPE标记化导致的推理干扰
- 每个单元格一个标记，无压缩

### 数据增强

- 贯穿全流程：训练、推理、评分
- 几何变换：D8对称（旋转+翻转）
- 颜色置换：10种颜色随机排列
- 示例对重排：改变示例顺序

## 2. 模型训练

### 模型选择

- Mistral-NeMo-Minitron-8B-Base（最佳）
- Llama-3.2-3B-Instruct-uncensored

### 两阶段微调

1. **初阶段预训练**：
   - 数据集：Re-ARC + 75%公开评估数据
   - 方法：LoRA适配器（rank=256）
   - 4-bit量化，梯度检查点

2. **次阶段测试时训练**：
   - 数据集：隐藏测试集
   - 方法：LoRA（rank=64），运行4轮
   - 在Kaggle环境中（2×T4 GPU）

### 训练参数

- 学习率：LoRA层1e-4，嵌入层1e-5
- 批次大小：4（本地）/2（Kaggle）
- 仅对输出网格计算梯度（不预测输入）

## 3. 推理生成

### DFS概率引导采样

- **替代贪婪/随机采样**
- 深度优先搜索，保留累积概率>阈值的路径
- 阈值p：10%-20%（Kaggle使用较高值减少运行时间）
- **关键优势**：保证找到概率>p的最佳解

### 多视角生成

- 对每个任务生成8-16个增强版本
- 分别进行DFS采样
- 汇集所有候选解（某些解在特定视角下更易发现）

## 4. 候选解选择

### 增强稳定性评分

- 对每个候选解，计算其在8种增强下的生成概率
- 评分公式：$score(s) = \prod_{i=1}^{8} P_i^{aug}(s)$
  - 或等价地：$\sum \log P_i^{aug}(s)$
- 选择得分最高的两个候选解提交

### 选择策略效果

- 相比基线提升约25%准确率
- 在100个任务中解决72.5个

## 5. 性能优化

### 并行化

- 将测试集分为两半，在两块GPU上并行运行
- 总训练时间：约5小时20分钟（Kaggle环境）

### 内存效率

- DFS一次只追踪单一路径，内存占用低
- 对比波束搜索：随波束数线性增长

## 6. 关键结果

- Kaggle ARC Prize 2024：53.5分（最终56.5分，第二名）
- 公开评估集（100任务）：解决72.5个
- 证明LLM可通过适当方法解决复杂ARC任务

## 7. 核心创新点

1. **全流程增强**：增强应用于训练、推理、评分各阶段
2. **DFS采样**：保证找到高概率解
3. **增强稳定性评分**：利用跨增强一致性筛选最佳解
4. **轻量级适配**：LoRA微调+4-bit量化，适应有限资源

---

# NVARC 核心方案要点

## 1. 核心创新：合成数据生成（SDG）

### 四阶段管道

1. **收集与生成谜题摘要**
   - 数据源：H-ARC（1700+人类描述）+ BARC（160人工描述）
   - LLM生成标准化摘要（5部分格式）
   - 最终：3268个任务摘要

2. **混合摘要创造复杂任务**
   - 采用INSTRUCT-SKILLMIX思想
   - 混合两个摘要生成更复杂新任务
   - 生成：26.6万+新摘要

3. **生成输入网格程序**
   - 根据摘要生成Python输入程序
   - **关键验证**：生成单元测试，要求程序能产生30+唯一输入网格且全部通过测试
   - 生成：12.7万+有效输入程序（接受率：易任务70%，难任务50%）

4. **生成输出网格程序**
   - 根据摘要+输入程序生成输出/变换程序
   - **关键验证**：对同一输入程序多次采样，只保留产生一致输出的程序
   - 最终：10.3万+完整合成谜题（每谜题30个输入输出对）

### 最终数据集

- 3.2M增强训练样本（来自32.8万独特任务）
- 每个样本最多7个输入输出对

## 2. 改进的ARCHitects方案（批处理DFS + 新评分公式 + bfloat16微调）

### 数据与训练

- **数据集组合**：合成数据 + MINI-ARC + ConceptARC + RE-ARC + ARC-AGI-2
- **简化表示**：采用Qwen对话模板，一个输入输出对仅需16种token
- **训练框架**：NeMo RL框架

### 测试时微调优化

- **LoRA配置**：r=256, alpha=32（比原始Architect更激进）
- **精度提升**：使用bfloat16（移除4-bit量化）
- **加速技术**：Flash Attention 2 + 移除梯度检查点
- **独立微调**：为每个测试任务独立运行LoRA微调

### 解码优化

- **批处理DFS**：实现DFS批处理版本，显著提升速度
- **非确定性问题**：尝试解决批处理引入的非确定性（因速度代价未采用）

### 候选解选择改进

- **增强一致性**：对所有候选解使用**完全相同的8种增强**
- **新评分公式**：
  
  score_agg(s) = 频率分 + 稳定性分 = ∑[c=s] + (1/m)∑log P_j(s)

  - **频率分**：候选解在DFS中被采样到的次数
  - **稳定性分**：在8种增强下对数概率的平均值
- 选择最高分候选解作为最终答案

## 3. 模型与结果

### 模型选择

- **主力模型**：Qwen3-4B-Thinking（最佳性能）
- **对比模型**：Qwen3-2B, Qwen3-VL-2B

### 关键结果

- **比赛期间**：27.64%准确率（公开榜第一）
- **赛后优化**：29.72%准确率（新SOTA）
- **效率**：以1/40计算成本超越其他方案

## 4. 工程优化要点

- **并行策略**：分割测试集，双GPU并行
- **内存管理**：减少数据规模，优化批处理
- **数据过滤**：放弃BARC数据集（根据往年经验无效）

## 5. 核心创新总结

1. **合成数据管道**：自动化、可扩展、高质量数据生成
2. **改进评分公式**：频率分+稳定性分，更鲁棒的选择策略
